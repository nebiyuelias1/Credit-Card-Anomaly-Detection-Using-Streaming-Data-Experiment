{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Streaming Data Anomaly Detection\n",
    "In this experiment, I'm trying to do anomaly detection of credit card streaming data. The models I'm using are semi-online, meaning the training data is used first for training, then the testing data is streamed to the model. The model updates itself during the streaming process. The models considered are:\n",
    "* IForestASD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make sure requirements are installed first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from pysad.models import IForestASD\n",
    "from pysad.transform.preprocessing import InstanceUnitNormScaler\n",
    "from pysad.transform.postprocessing import RunningAveragePostprocessor\n",
    "from pysad.utils import Data\n",
    "from pysad.evaluation import AUROCMetric, PrecisionMetric, RecallMetric\n",
    "from pysad.utils.array_streamer import ArrayStreamer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import date, datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These are just utility functions used for extracting features from the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the label and features of the given dataframe\n",
    "def get_label_and_features(df):\n",
    "    # This function converts given date to age \n",
    "    def age(born): \n",
    "        born = datetime.strptime(born, \"%Y-%m-%d\").date() \n",
    "        today = date.today() \n",
    "        return today.year - born.year - ((today.month,  \n",
    "                                        today.day) < (born.month,  \n",
    "                                                        born.day))\n",
    "    \n",
    "    # Assuming the 'is_fraud' column contains the labels (1 for fraud, 0 for normal)\n",
    "    labels = df['is_fraud']\n",
    "\n",
    "    # Drop non-numeric columns and the label column\n",
    "    features = df.drop(['merchant', 'first', 'last', \n",
    "                        'street', 'city', 'state', 'job', 'dob', 'trans_num', 'is_fraud'], axis=1)\n",
    "\n",
    "    # Convert time string to timestamp\n",
    "    features['trans_date_trans_time'] = pd.to_datetime(features['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S').astype(np.int64)\n",
    "\n",
    "    # Changing categorical data to numerical data\n",
    "    features['category'] = pd.Categorical(features['category'])\n",
    "    features['category'] = features['category'].cat.codes\n",
    "\n",
    "    features['gender'] = pd.Categorical(features['gender'])\n",
    "    features['gender'] = features['gender'].cat.codes\n",
    "\n",
    "    # Calculate current age\n",
    "    features['age'] = df['dob'].apply(age)\n",
    "\n",
    "    return labels, features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read The Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV using pandas\n",
    "# index_col='Unnamed: 0' is used to ignore the first column\n",
    "training_df = pd.read_csv('data/fraudTrain.csv', index_col='Unnamed: 0')\n",
    "\n",
    "_, training_features = get_label_and_features(training_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do the training on the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train IForestASD model\n",
    "model = IForestASD()\n",
    "model.fit(training_features.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read The Streaming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV using pandas\n",
    "# index_col='Unnamed: 0' is used to ignore the first column\n",
    "df = pd.read_csv('data/fraudTest.csv', index_col='Unnamed: 0')\n",
    "labels, features = get_label_and_features(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "features, labels = shuffle(features, labels)\n",
    "\n",
    "iterator = ArrayStreamer(shuffle=False)  # Init streamer to simulate streaming data.\n",
    "\n",
    "preprocessor = InstanceUnitNormScaler()  # Init normalizer.\n",
    "postprocessor = RunningAveragePostprocessor(window_size=5)  # Init running average postprocessor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = AUROCMetric()  # Init area under the receiver-operating characteristics curve metric.\n",
    "precision = PrecisionMetric() # Init precision metric.\n",
    "recall = RecallMetric() # Init recall metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stream the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 100\n",
    "end_idx = 1000\n",
    "for X, y in tqdm(iterator.iter(features.values[start_idx: end_idx], labels.values[start_idx: end_idx])):  # Stream data.\n",
    "    # Apply preprocessing and postprocessing.\n",
    "    X_numeric = preprocessor.fit_transform_partial(X)\n",
    "    X = X_numeric  # Replace the transformed elements back into the original array\n",
    "    \n",
    "    score = model.fit_score_partial(X)  # Fit model to and score the instance.\n",
    "    score = postprocessor.fit_transform_partial(score)  # Apply running averaging to the score.\n",
    "\n",
    "    auroc.update(y, score)  # Update AUROC metric.\n",
    "    precision.update(y, score)  # Update precision metric.\n",
    "    recall.update(y, score)  # Update recall metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output resulting AUROCS metric.\n",
    "print(\"AUROC: \", auroc.get())\n",
    "print(\"Precision: \", precision.get())\n",
    "print(\"Recall: \", recall.get())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
